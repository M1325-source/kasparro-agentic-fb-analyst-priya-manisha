ğŸŒŸ Kasparro â€” Agentic Facebook Performance Analyst (v1.0)

An AI-native, multi-agent diagnostic engine that explains why ROAS changed, validates hypotheses quantitatively, and generates data-grounded creative improvements â€” designed for real-world marketing workflows.

ğŸš€ Overview

This project builds a production-style agentic system aligned with Kasparroâ€™s applied-AI philosophy:

Multi-agent orchestration

Structured reasoning + validation

RAG-style summarization

Creative generation grounded in historic messaging

Configuration management across environments

Observability + reliability baked in

Designed to be modular, testable, debuggable, and easy to extend.

ğŸ§  System Capabilities
âœ” Diagnose ROAS fluctuations

Quantifies ROAS change across time windows, identifies potential causes.

âœ” Identify performance drivers

Campaign-level CTR, ROAS, impressions, frequency patterns.

âœ” Generate hypotheses

Creatively but consistently structured (Think â†’ Analyze â†’ Conclude).

âœ” Quantitative validation

Evaluator converts qualitative hypotheses into numeric confidence & evidence.

âœ” Generate new creatives

For low-CTR campaigns: headlines, primary text, CTA â€” grounded in dataset vocabulary.

âœ” Build production outputs

Writes:

reports/insights.json

reports/creatives.json

reports/report.md

âœ” Logging & observability

Every agent logs JSON events to logs/run_logs.jsonl.

âš™ï¸ Quick Start
# 1. Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows

# 2. Install dependencies
pip install -r requirements.txt

# 3. Choose environment (dev/stage/prod/p2)
set ENV=dev

# 4. Run analysis
python src/run.py "Analyze ROAS drop in last 30 days"

ğŸ§© Architecture Diagram
flowchart TD
  U[User Query] --> P[Planner Agent]
  P -->|subtasks| DA[Data Agent]
  DA -->|summary| IA[Insight Agent]
  IA -->|hypotheses| EV[Evaluator Agent]
  EV -->|validated insights| P
  P --> CG[Creative Generator]
  CG --> R[Report Builder]
  
  subgraph Logs
    L((JSON Logs))
  end
  
  DA -.-> L
  IA -.-> L
  EV -.-> L
  CG -.-> L
  P -.-> L
  R -.-> L

ğŸ“¦ Repository Structure
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/         # All agents + retry
â”‚   â”œâ”€â”€ utils/          # logger, config, data-source loaders
â”‚   â””â”€â”€ run.py          # main orchestrator
â”œâ”€â”€ config/             # dev, prod, stage, p2 configs
â”œâ”€â”€ reports/            # generated insights + creatives
â”œâ”€â”€ logs/               # structured JSON logs
â”œâ”€â”€ tests/              # unit + integration tests
â”œâ”€â”€ prompts/            # structured prompts
â””â”€â”€ README.md

ğŸ—ï¸ Engineering Progress (Original â†’ Improved)
ğŸ”µ Initial Version

You originally built:

Core multi-agent system

ROAS diagnosis

Hypothesis generation via structured prompts

Creative generation

Basic insights & creatives JSON

Clean architecture + README

v1.0 release

This met the assignment baseline.

ğŸ”¥ P0 Improvements â€” Production Foundations

"Add structured logging, validation, tests." â€” Kasparro review feedback

âœ” Structured Logging

Added logger.py

Every agent logs JSONL events (timestamp, agent, meta)

âœ” Data Validation

Missing columns

Type mismatches

Outlier detection

NaN recovery

Logged with severity tags

âœ” Unit Tests

test_data_agent.py

test_evaluator.py
Ensures schema correctness & confidence logic.

âœ” Config Versioning (dev/prod)

Environment-based configuration loader.

âš¡ P1 Improvements â€” Reliability & Correctness

"Smarter retry, versioned configs, integration tests."

âœ” Backoff Retry Logic

Linear, configurable wait times to handle low-confidence evaluations.

âœ” Multi-Environment Config Loader

config/dev.yaml, stage.yaml, prod.yaml

âœ” Integration Tests

Ensures pipeline consistency across multiple runs.

ğŸš€ P2 Improvements â€” Scalability & Extensibility

"Adaptive behavior + multi-source support."

âœ” Adaptive Data Strategy

Small datasets â†’ full load
Medium â†’ sampling
Large â†’ stratified sampling

âœ” Multi-Source Loader

Supports:

CSV

JSON

Extensible future connectors

âœ” Additional Tests

Adaptivity behavior

Multi-source validation

ğŸ“Š Sample Output Formats
insights.json
{
  "roas_change_pct": -0.28,
  "hypotheses": [
    {
      "hypothesis": "CTR decline due to creative fatigue",
      "confidence": 0.76,
      "evidence": "median_ctr=0.021, worst_ctr=0.012, delta=-0.35"
    }
  ]
}

creatives.json
[
  {
    "campaign_name": "ComfortWear",
    "suggestions": [
      {"headline": "Feel the Softness", "text": "All-day comfort you can trust.", "cta": "Shop Now"}
    ]
  }
]

ğŸ§ª Testing
pytest -q


Includes:

Unit tests

Evaluator tests

Integration tests

Adaptivity + source loading tests

ğŸ”— Releases & PRs

v1.0 Release:
https://github.com/M1325-source/kasparro-agentic-fb-analyst-priya-manisha/releases/tag/v1.0

P0 PR: improvements-p0  - https://github.com/M1325-source/kasparro-agentic-fb-analyst-priya-manisha/tree/improvements-p0

P1 PR: improvements-p1 - https://github.com/M1325-source/kasparro-agentic-fb-analyst-priya-manisha/tree/improvements-p1

P2 PR: improvements-p2 - https://github.com/M1325-source/kasparro-agentic-fb-analyst-priya-manisha/tree/improvements-p2

(List your PR links here if you want â€” I can add them.)
